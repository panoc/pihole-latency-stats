#!/bin/bash
# ==============================================================================
# Script:      Pi-hole Latency Stats
# Description: Lightweight dashboard for Pi-hole latency & Unbound DNS cache stats.
# Author:      panoc
# GitHub:      https://github.com/panoc/pihole-latency-stats
# License:     GPLv3
# ==============================================================================
# Copyright (C) 2026 panoc <https://github.com/panoc>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
# ==============================================================================

VERSION="v3.6.1"
UPDATE_MSG=""


# --- 0. CRITICAL LOCALE FIX ---
# Force C locale to prevent decimal errors (comma vs dot) in math operations
export LC_ALL=C

# Capture start time
START_TS=$(date +%s.%N 2>/dev/null)
if [[ "$START_TS" == *N* ]] || [ -z "$START_TS" ]; then START_TS=$(date +%s); fi

# --- TRAP: CUSTOM ABORT MESSAGE ---
# Catches Ctrl+C (INT), prints message, and exits (which triggers the cleanup trap)
trap 'echo -e "\n\nProgram aborted by user." >&2; exit 1' INT

# --- 1. SETUP & DEFAULTS ---
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" &> /dev/null && pwd)"
V_LOCAL_FILE="$(dirname "$0")/version"
DEFAULT_CONFIG="$SCRIPT_DIR/pihole_stats.conf"
CONFIG_TO_LOAD="$DEFAULT_CONFIG"

# Internal Defaults (used if config is missing or empty)
DBfile="/etc/pihole/pihole-FTL.db"
SAVE_DIR_TXT=""
SAVE_DIR_JSON=""
TXT_NAME=""
JSON_NAME=""
CONFIG_ARGS=""
MAX_LOG_AGE=""
ENABLE_UNBOUND="auto"
LAYOUT="auto"
DEFAULT_FROM=""
DEFAULT_TO=""
MIN_LATENCY_CUTOFF=""
MAX_LATENCY_CUTOFF=""

# Dashboard History Defaults
MAX_HISTORY_ENTRIES="8640"
DASH_DIR="/var/www/html/admin/img/dash"

# --- ANIMATION SETTINGS (Hardcoded) ---
target_time=4.0      # Seconds for one full cycle
width_divider=3      # 1/3 of screen width
char="|"             # Character for the bar

# Default Tiers
L01="0.009"; L02="0.1"; L03="1"; L04="10"; L05="50"
L06="100"; L07="300"; L08="1000"
L09=""; L10=""; L11=""; L12=""; L13=""; L14=""; L15=""; L16=""; L17=""; L18=""; L19=""; L20=""

# Default Time Range
QUERY_START=0
QUERY_END=$(date +%s)
TIME_LABEL="All Time"

# --- HELPER: FIX PERMISSIONS ---
fix_perms() {
    local target="$1"
    local mode="$2" # Optional: "dash" (force www-data) or "user" (force real user)

    if [ ! -e "$target" ]; then return; fi

    # Mode 1: Dashboard Files (Strictly www-data for web server access)
    # Applies if explicitly requested OR if the path is within the dash directory
    if [[ "$mode" == "dash" ]] || [[ "$target" == "$DASH_DIR"* ]]; then
        chown www-data:www-data "$target" 2>/dev/null
        chmod 664 "$target" 2>/dev/null

    # Mode 2: User Files (Strictly SUDO_USER for CLI usability)
    # This ensures files generated by -j/-f or debug logs are editable by the user without sudo
    elif [ -n "$SUDO_UID" ] && [ -n "$SUDO_GID" ]; then
        chown "$SUDO_UID:$SUDO_GID" "$target"
        chmod 644 "$target"
    fi
}

# --- 2. CONFIGURATION WRITER ---
write_config() {
    local target_file="$1"

    # We use cat to write the file, injecting current variable values
    cat <<EOF > "$target_file"
# ================= PI-HOLE STATS CONFIGURATION =================
DBfile="$DBfile"

# Default Save Directories (REQUIRED for Auto-Deletion to work)
# Separate directories for Text and JSON reports.
# If left empty, files are saved in the current directory.

# Text Reports (.txt)
# Example: SAVE_DIR_TXT="/home/pi/pihole_reports/text"
SAVE_DIR_TXT="$SAVE_DIR_TXT"

# JSON Reports (.json)
# Example: SAVE_DIR_JSON="/home/pi/pihole_reports/json"
SAVE_DIR_JSON="$SAVE_DIR_JSON"

# Dashboard Settings
# Directory where dash_[profile].json files are saved.
DASH_DIR="$DASH_DIR"
# Max entries for the history file (dash_default.h.json). 
# 8640 entries = 30 days at 5 min interval.
MAX_HISTORY_ENTRIES="$MAX_HISTORY_ENTRIES"

# Default Filenames (If set, the -f flag is no longer required)
# Example: TXT_NAME="daily_report.txt"
# Example: JSON_NAME="dash_default.json"
TXT_NAME="$TXT_NAME"
JSON_NAME="$JSON_NAME"

# Auto-Delete Old Reports (Retention Policy)
# Delete files in SAVE_DIR_TXT and SAVE_DIR_JSON older than X days.
# Example: MAX_LOG_AGE="30"
MAX_LOG_AGE="$MAX_LOG_AGE"

# Unbound Integration
# auto  : Check if Unbound is installed & used by Pi-hole.
# true  : Always append Unbound stats.
# false : Never show Unbound stats (unless -unb is used).
ENABLE_UNBOUND="$ENABLE_UNBOUND"

# Visual Layout
# auto       : Detects terminal width. >100 columns = Horizontal, else Vertical.
# vertical   : Forces standard vertical list view.
# horizontal : Forces split-pane dashboard view.
LAYOUT="$LAYOUT"

# Custom Date Range Defaults (Optional)
# Use natural language (e.g. "yesterday", "today 00:00") or dates.
# CLI flags (-24h, -from) will OVERRIDE these settings.
DEFAULT_FROM="$DEFAULT_FROM"
DEFAULT_TO="$DEFAULT_TO"

# [OPTIONAL] Default Arguments
# If set, these arguments will REPLACE any CLI flags.
# Use single quotes if your arguments contain filenames with spaces.
# Example: CONFIG_ARGS='-up -24h -j -f "my stats.json"'
CONFIG_ARGS='$CONFIG_ARGS'

# Latency Tiers (Upper Limits in Milliseconds)
# Add more values (L09, L10...) to create granular buckets.
L01="$L01"
L02="$L02"
L03="$L03"
L04="$L04"
L05="$L05"
L06="$L06"
L07="$L07"
L08="$L08"
L09="$L09"
L10="$L10"
L11="$L11"
L12="$L12"
L13="$L13"
L14="$L14"
L15="$L15"
L16="$L16"
L17="$L17"
L18="$L18"
L19="$L19"
L20="$L20"

# Latency Cutoffs (Optional Settings)
# Filter queries from the analysis based on response time (in milliseconds).
# Any query falling outside these bounds will be excluded from the Analyzed count,
# Average/Median/P95 calculations, and the Tier distribution graph.
# 
# MIN_LATENCY_CUTOFF: Useful to ignore instant/cached queries (e.g., set to 1).
# MAX_LATENCY_CUTOFF: Useful to ignore extreme outliers/timeouts (e.g., set to 500).
# Leave empty to disable.
MIN_LATENCY_CUTOFF="$MIN_LATENCY_CUTOFF"
MAX_LATENCY_CUTOFF="$MAX_LATENCY_CUTOFF"
EOF
    chmod 644 "$target_file"
    fix_perms "$target_file" "user"
}

create_or_update_config() {
    local target_file="$1"
    if [ -f "$target_file" ]; then source "$target_file"; fi
    write_config "$target_file"
}

# --- 3. PRE-SCAN FLAGS ---
args_preserve=("$@") 
while [[ $# -gt 0 ]]; do
    case $1 in
        -c|--config) shift; CONFIG_TO_LOAD="$1"; shift ;;
        -mc|--make-config) shift; create_or_update_config "$1"; exit 0 ;;
        *) shift ;;
    esac
done

# --- 4. LOAD CONFIG ---
if [ -f "$CONFIG_TO_LOAD" ]; then 
    source "$CONFIG_TO_LOAD"

    # Backward Compatibility: Map old SAVE_DIR to SAVE_DIR_TXT if needed
    if [ -n "$SAVE_DIR" ] && [ -z "$SAVE_DIR_TXT" ]; then
        SAVE_DIR_TXT="$SAVE_DIR"
    fi

    # Auto-Repair/Update Config: If new variables are missing OR old animation vars exist, rewrite the file
    if ! grep -q "JSON_NAME=" "$CONFIG_TO_LOAD" || grep -q "target_time=" "$CONFIG_TO_LOAD" || ! grep -q "MAX_LATENCY_CUTOFF=" "$CONFIG_TO_LOAD"; then
        write_config "$CONFIG_TO_LOAD"
    fi
elif [ "$CONFIG_TO_LOAD" == "$DEFAULT_CONFIG" ]; then
    write_config "$DEFAULT_CONFIG" > /dev/null; source "$DEFAULT_CONFIG"
fi

if [ -n "$DEFAULT_FROM" ]; then if TS=$(date -d "$DEFAULT_FROM" +%s 2>/dev/null); then QUERY_START="$TS"; TIME_LABEL="Custom Range"; fi; fi
if [ -n "$DEFAULT_TO" ]; then if TS=$(date -d "$DEFAULT_TO" +%s 2>/dev/null); then QUERY_END="$TS"; TIME_LABEL="Custom Range"; fi; fi
if [ -n "$CONFIG_ARGS" ]; then eval set -- "$CONFIG_ARGS"; else set -- "${args_preserve[@]}"; fi

# --- 5. HELP ---
show_help() {
    echo "Pi-hole Latency Stats $VERSION"
    echo "Usage: sudo ./pihole_stats.sh [OPTIONS]"
    echo "  -dash [profile]    : Run in Dashboard Mode (Snapshot + History)"
    echo "  -nh                : No History (use with -dash)"
    echo "  -clear             : Clear history file for profile (use with -dash)"
    echo "  -24h, -7d          : Quick time filter"
    echo "  -from, -to         : Custom date range"
    echo "  -up, -pi, -nx      : Query modes"
    echo "  -dm, -edm          : Domain filter"
    echo "  -j [file]          : Save JSON output (Optional: custom path)"
    echo "  -f [file]          : Save Text output (Optional: custom path)"
    echo "  -s                 : Silent mode"
    echo "  -seq, -ts          : Naming options"
    echo "  -rt <days>         : Auto-delete old reports"
    echo "  -unb, -unb-only    : Unbound Stats"
    echo "  -ucc               : Unbound Cache Count"
    echo "  -hor, -ver         : Force Layout"
    echo "  -snap              : Snapshot Mode"
    echo "  -c, -mc            : Config (Load/Make)"
    echo "  -debug             : Run UCC mode & log errors to pihole_stats_debug.log"
    echo "  To Uninstall       : Run ./phls_uninstall.sh (created during install)"
    exit 0
}

# --- 6. ARGUMENTS ---
MODE="DEFAULT"; EXCLUDE_NX=false; SILENT_MODE=false
DOMAIN_FILTER=""; SQL_DOMAIN_CLAUSE=""; SEQUENTIAL=false; ADD_TIMESTAMP=false
SHOW_UNBOUND="default"; USE_SNAPSHOT=false; ENABLE_UCC=false; DEBUG_MODE=false
DEBUG_LOG="$SCRIPT_DIR/pihole_stats_debug.log"

# Output Logic Variables
DO_JSON=false; JSON_FILE=""
DO_TXT=false; TXT_FILE=""

# Dashboard Specific Flags
DASH_MODE=false; DASH_PROFILE="default"; DASH_HISTORY=true; DASH_CLEAR=false
LOCK_FILE="/tmp/phls.lock"

# Parse arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -h|--help) show_help ;;
        -c|--config|-mc|--make-config) shift; shift ;;

        # Dashboard Flags
        -dash) 
            DASH_MODE=true; DO_JSON=true; SILENT_MODE=true
            if [[ -n "$2" && "$2" != -* ]]; then DASH_PROFILE="$2"; shift; fi
            shift ;;
        -nh) DASH_HISTORY=false; shift ;;
        -clear) DASH_CLEAR=true; shift ;;

        # Standard Flags
        -up) [ "$DASH_MODE" = false ] && MODE="UPSTREAM"; shift ;;
        -pi) [ "$DASH_MODE" = false ] && MODE="PIHOLE"; shift ;;
        -nx) [ "$DASH_MODE" = false ] && EXCLUDE_NX=true; shift ;;

        # New Output Logic (-j and -f)
        -j|--json)
            DO_JSON=true
            # Check if next argument is a filename (not a flag)
            if [[ -n "$2" && "$2" != -* ]]; then JSON_FILE="$2"; shift; fi
            shift ;;
        -f)
            DO_TXT=true
            # Check if next argument is a filename (not a flag)
            if [[ -n "$2" && "$2" != -* ]]; then TXT_FILE="$2"; shift; fi
            shift ;;

        -s|--silent) SILENT_MODE=true; shift ;;
        -seq) SEQUENTIAL=true; shift ;;
        -ts|--timestamp) ADD_TIMESTAMP=true; shift ;;
        -db) shift; DBfile="$1"; shift ;;
        -rt|--retention) shift; MAX_LOG_AGE="$1"; shift ;;
        -unb) SHOW_UNBOUND="yes"; shift ;;
        -unb-only) SHOW_UNBOUND="only"; shift ;;
        -no-unb) SHOW_UNBOUND="no"; shift ;;
        -snap) USE_SNAPSHOT=true; shift ;;
        -ucc) ENABLE_UCC=true; shift ;;
        -debug) DEBUG_MODE=true; ENABLE_UCC=true; shift ;;
        -hor|--horizontal) LAYOUT="horizontal"; shift ;;
        -ver|--vertical) LAYOUT="vertical"; shift ;;
        -from|--start) 
            if [ "$DASH_MODE" = false ]; then
                shift; QUERY_START=$(date -d "$1" +%s); TIME_LABEL="Custom Range"
            else shift; fi
            shift ;;
        -to|--end) 
            if [ "$DASH_MODE" = false ]; then
                shift; QUERY_END=$(date -d "$1" +%s); TIME_LABEL="Custom Range"
            else shift; fi
            shift ;;
        -dm|--domain) shift; DOMAIN_FILTER="$1"; SANITIZED="${1//\*/%}"; SANITIZED="${SANITIZED//\?/_}"; SQL_DOMAIN_CLAUSE="AND domain LIKE '%$SANITIZED%'"; shift ;;
        -edm|--exact-domain) shift; DOMAIN_FILTER="$1"; SANITIZED="${1//\*/%}"; SANITIZED="${SANITIZED//\?/_}"; SQL_DOMAIN_CLAUSE="AND (domain LIKE '$SANITIZED' OR domain LIKE '%.$SANITIZED')"; shift ;;

        # Legacy/Shortcut Time Arguments
        -*)
            if [ "$DASH_MODE" = false ]; then
                INPUT="${1#-}"
                if [[ "$INPUT" =~ ^[0-9]+[hd]$ ]]; then
                    UNIT="${INPUT: -1}"; VALUE="${INPUT:0:${#INPUT}-1}"
                    if [[ "$UNIT" == "h" ]]; then OFFSET=$((VALUE * 3600)); TIME_LABEL="Last $VALUE Hours"; fi
                    if [[ "$UNIT" == "d" ]]; then OFFSET=$((VALUE * 86400)); TIME_LABEL="Last $VALUE Days"; fi
                    QUERY_START=$(( $(date +%s) - OFFSET )); QUERY_END=$(date +%s)
                else echo "âŒ Error: Invalid arg '$1'" >&2; exit 1; fi
            fi
            shift ;;
        *) echo "âŒ Error: Unknown argument '$1'"; exit 1 ;;
    esac
done

# --- RESOLVE OUTPUT FILENAMES (Inheritance Logic) ---
if [ "$DASH_MODE" = false ]; then
    # 0. Handle Directory Inputs (User provided a folder via -j or -f)
    if [ -n "$JSON_FILE" ]; then
        if [ -d "$JSON_FILE" ] || [[ "$JSON_FILE" == */ ]]; then
            FNAME="${JSON_NAME:-pihole_stats.json}"
            JSON_FILE="${JSON_FILE%/}/$FNAME"
        fi
    fi
    if [ -n "$TXT_FILE" ]; then
        if [ -d "$TXT_FILE" ] || [[ "$TXT_FILE" == */ ]]; then
            FNAME="${TXT_NAME:-pihole_stats.txt}"
            TXT_FILE="${TXT_FILE%/}/$FNAME"
        fi
    fi

    # 1. If -j provided but no file, try to inherit from -f or use default
    if [ "$DO_JSON" = true ] && [ -z "$JSON_FILE" ]; then
        if [ -n "$TXT_FILE" ]; then 
            JSON_FILE="${TXT_FILE%.*}.json"
        elif [ -n "$JSON_NAME" ]; then 
            JSON_FILE="$JSON_NAME"
        else 
            JSON_FILE="$PWD/pihole_stats.json" # Force PWD if manual flag
        fi
    fi

    # 2. If -f provided but no file, try to inherit from -j or use default
    if [ "$DO_TXT" = true ] && [ -z "$TXT_FILE" ]; then
        if [ -n "$JSON_FILE" ]; then 
            TXT_FILE="${JSON_FILE%.*}.txt"
        elif [ -n "$TXT_NAME" ]; then 
            TXT_FILE="$TXT_NAME"
        else 
            TXT_FILE="$PWD/pihole_stats.txt" 
        fi
    fi

    # 3. Apply Directory Prefixes if path is not absolute
    if [ -n "$JSON_FILE" ] && [[ "$JSON_FILE" != /* ]] && [ -n "$SAVE_DIR_JSON" ]; then 
        mkdir -p "$SAVE_DIR_JSON"; JSON_FILE="$SAVE_DIR_JSON/$JSON_FILE"
    fi
    if [ -n "$TXT_FILE" ] && [[ "$TXT_FILE" != /* ]] && [ -n "$SAVE_DIR_TXT" ]; then 
        mkdir -p "$SAVE_DIR_TXT"; TXT_FILE="$SAVE_DIR_TXT/$TXT_FILE"
    fi
fi
if [ "$DASH_MODE" = false ]; then
    if [ "$TIME_LABEL" == "Custom Range" ]; then TIME_LABEL="$(date -d @$QUERY_START "+%Y-%m-%d %H:%M") to $(date -d @$QUERY_END "+%Y-%m-%d %H:%M")"; fi
    if [ "$LAYOUT" == "auto" ]; then COLS=$(tput cols 2>/dev/null || echo 80); if [ "$COLS" -ge 100 ]; then LAYOUT="horizontal"; else LAYOUT="vertical"; fi; fi
    if [ "$SHOW_UNBOUND" == "only" ]; then LAYOUT="vertical"; fi
fi

# --- 7. DASHBOARD SPECIAL COMMANDS & LOCK ---
if [ "$DASH_MODE" = true ]; then
    HIST_PATH="${DASH_DIR}/dash_${DASH_PROFILE}.h.json"
    SNAP_PATH="${DASH_DIR}/dash_${DASH_PROFILE}.json"

    # -clear COMMAND Logic
    if [ "$DASH_CLEAR" = true ]; then
        echo -n "âš ï¸  Clear history for profile '$DASH_PROFILE'? [y/N]: "
        read -r confirm
        if [[ "$confirm" =~ ^[Yy]$ ]]; then
            rm -f "$HIST_PATH" && echo "âœ… History cleared for profile: $DASH_PROFILE" || echo "âŒ Error clearing file."
        else
            echo "Aborted."
        fi
        exit 0
    fi

    # LOCK MECHANISM
    if [ -f "$LOCK_FILE" ]; then
        LOCK_PID=$(cat "$LOCK_FILE" 2>/dev/null)
        if [ -n "$LOCK_PID" ] && ps -p "$LOCK_PID" > /dev/null; then
            # Silent exit if locked to prevent cron pile-up
            if [ "$DEBUG_MODE" = true ]; then echo "[$(date)] Locked by PID $LOCK_PID" >> "$DEBUG_LOG"; fi
            exit 1
        fi
    fi
    echo $$ > "$LOCK_FILE"
    # Ensure lock is removed on exit
#    trap 'rm -f "$LOCK_FILE"; tput cnorm >&2' EXIT
trap 'rm -f "$LOCK_FILE"; [ -t 1 ] && tput cnorm >&2 2>/dev/null' EXIT
fi

# --- 8. ANIMATION LOGIC ---
start_spinner() {
    # Run in background
    (
        term_cols=$(tput cols 2>/dev/null || echo 80)
        width=$(( term_cols / width_divider ))
        # Ensure min width for visual sanity
        [ "$width" -lt 5 ] && width=5

        start_len=$(( width % 2 == 0 ? 2 : 1 ))
        frames=()

        # Phase A: Grow
        for (( len=start_len; len<=width; len+=2 )); do
            padding=$(( (width - len) / 2 )); pad=$(printf "%${padding}s")
            printf -v bar_raw "%*s" "$len" ""; bar="${bar_raw// /$char}"
            frames+=("|$pad$bar$pad|")
        done

        # Phase B: Shrink
        for (( len=width-2; len>=start_len; len-=2 )); do
            padding=$(( (width - len) / 2 )); pad=$(printf "%${padding}s")
            printf -v bar_raw "%*s" "$len" ""; bar="${bar_raw// /$char}"
            frames+=("|$pad$bar$pad|")
        done

        interval=$(awk "BEGIN {print $target_time / ${#frames[@]}}")
        tput civis >&2 # Hide cursor
        while true; do
            for frame in "${frames[@]}"; do
                tput rc >&2; printf "%s" "$frame" >&2; sleep "$interval"
            done
        done
    ) &
    SPINNER_PID=$!
    # Trap only EXIT (fixes double Ctrl+C issue)
#    trap 'kill $SPINNER_PID 2>/dev/null; echo "" >&2; tput cnorm >&2' EXIT
trap 'kill $SPINNER_PID 2>/dev/null; [ -t 1 ] && tput cnorm >&2 2>/dev/null' EXIT
}

stop_spinner() {
    if [ -n "$SPINNER_PID" ]; then
        kill "$SPINNER_PID" 2>/dev/null
        wait "$SPINNER_PID" 2>/dev/null
        # Only use tput if we are in an interactive terminal
        if [ -t 1 ]; then
            tput rc >&2; tput el >&2; echo "Finished!" >&2; tput cnorm >&2
        else
            echo "Finished!" >&2
        fi
        SPINNER_PID=""
        trap - EXIT
    fi
}

# --- 9. DATA COLLECTION (UNBOUND) ---
U_STATUS="Disabled"; U_TOTAL="0"; U_HITS="0"; U_MISS="0"; U_PRE="0"; 
U_PCT_HIT="0.00"; U_PCT_MISS="0.00"; U_PCT_PRE="0.00"
U_MEM_MSG="0"; U_MEM_RR="0"; U_LIM_MSG="0"; U_LIM_RR="0"
U_PCT_MEM_MSG="0.00"; U_PCT_MEM_RR="0.00"; UCC_MSG="0"; UCC_RR="0"; HAS_UNBOUND=false

collect_unbound_stats() {
    if [ "$SHOW_UNBOUND" == "no" ]; then return; fi
    if ! command -v unbound-control &> /dev/null; then 
        [ "$SHOW_UNBOUND" == "yes" ] || [ "$SHOW_UNBOUND" == "only" ] && echo "Error: unbound-control not found" >&2
        [ "$DEBUG_MODE" = true ] && echo "[$(date)] Error: unbound-control not found" >> "$DEBUG_LOG"
        return
    fi

    if [ "$SHOW_UNBOUND" == "default" ]; then
        if [ "$ENABLE_UNBOUND" == "false" ]; then return; fi
        if [ "$ENABLE_UNBOUND" == "auto" ]; then
            IS_RUNNING=false
            if systemctl is-active --quiet unbound 2>/dev/null || pgrep -x unbound >/dev/null; then IS_RUNNING=true; fi
            if [ "$IS_RUNNING" = false ]; then return; fi
            if ! grep -qE "PIHOLE_DNS_.*=(127\.0\.0\.1|::1)" /etc/pihole/setupVars.conf 2>/dev/null && \
               ! grep -qE "^server=(127\.0\.0\.1|::1)" /etc/dnsmasq.d/*.conf 2>/dev/null && \
               ! grep -F "127.0.0.1" /etc/pihole/pihole.toml >/dev/null 2>&1; then return; fi
        fi
    fi

    RAW_STATS=$(sudo /usr/sbin/unbound-control -c /etc/unbound/unbound.conf stats_noreset 2>&1)
# --- ADD THESE FOR DEBUGGING ---
if [ "$DEBUG_MODE" = true ]; then
    echo "[$(date)] RAW UNBOUND OUTPUT: $RAW_STATS" >> "$DEBUG_LOG"
fi
    if [ -z "$RAW_STATS" ] || echo "$RAW_STATS" | grep -iEq "^error:|connection refused"; then
         HAS_UNBOUND=true; U_STATUS="Error (Check Perms)"
         [ "$DEBUG_MODE" = true ] && echo "[$(date)] Unbound stats error: $RAW_STATS" >> "$DEBUG_LOG"
         return
    fi

    HAS_UNBOUND=true; U_STATUS="Active (Integrated)"
    U_HITS=$(echo "$RAW_STATS" | grep '^total.num.cachehits=' | cut -d= -f2); U_HITS=${U_HITS:-0}
    U_MISS=$(echo "$RAW_STATS" | grep '^total.num.cachemiss=' | cut -d= -f2); U_MISS=${U_MISS:-0}
    U_PRE=$(echo "$RAW_STATS" | grep '^total.num.prefetch=' | cut -d= -f2); U_PRE=${U_PRE:-0}
    U_TOTAL=$((U_HITS + U_MISS))

    if [ "$U_TOTAL" -gt 0 ]; then
        U_PCT_HIT=$(awk "BEGIN {printf \"%.2f\", ($U_HITS / $U_TOTAL) * 100}")
        U_PCT_MISS=$(awk "BEGIN {printf \"%.2f\", ($U_MISS / $U_TOTAL) * 100}")
    fi
    if [ "$U_HITS" -gt 0 ]; then U_PCT_PRE=$(awk "BEGIN {printf \"%.2f\", ($U_PRE / $U_HITS) * 100}"); fi

    U_MEM_MSG=$(echo "$RAW_STATS" | grep '^mem.cache.message=' | cut -d= -f2); U_MEM_MSG=${U_MEM_MSG:-0}
    U_MEM_RR=$(echo "$RAW_STATS" | grep '^mem.cache.rrset=' | cut -d= -f2); U_MEM_RR=${U_MEM_RR:-0}
    U_LIM_MSG=$(sudo /usr/sbin/unbound-checkconf -o msg-cache-size 2>/dev/null || echo "4194304")
    U_LIM_RR=$(sudo /usr/sbin/unbound-checkconf -o rrset-cache-size 2>/dev/null || echo "8388608")
    U_PCT_MEM_MSG=$(awk "BEGIN {printf \"%.2f\", ($U_MEM_MSG / $U_LIM_MSG) * 100}")
    U_PCT_MEM_RR=$(awk "BEGIN {printf \"%.2f\", ($U_MEM_RR / $U_LIM_RR) * 100}")

    if [ "$ENABLE_UCC" = true ]; then
        UCC_ERR_TMP=$(mktemp)
        eval $(sudo /usr/sbin/unbound-control dump_cache 2> "$UCC_ERR_TMP" | awk '/^msg/ {m++} /^;rrset/ {r++} END {print "UCC_MSG="m+0; print "UCC_RR="r+0}')
        if [ "$DEBUG_MODE" = true ] && [ -s "$UCC_ERR_TMP" ]; then
            echo "[$(date)] UCC dump error:" >> "$DEBUG_LOG"
            cat "$UCC_ERR_TMP" >> "$DEBUG_LOG"
        fi
        rm -f "$UCC_ERR_TMP"
        UCC_MSG=${UCC_MSG:-0}; UCC_RR=${UCC_RR:-0}
    fi
}
to_mb() { awk "BEGIN {printf \"%.2f\", $1 / 1024 / 1024}"; }

# --- 10. DATA COLLECTION (PI-HOLE) ---
P_TOTAL=0; P_INVALID=0; P_VALID=0; P_BLOCKED=0; P_ANALYZED=0; P_IGNORED=0
P_AVG="0.00"; P_MED="0.00"; P_95="0.00"; P_STD="0.00"
declare -a TIER_LABELS; declare -a TIER_COUNTS; declare -a TIER_PCTS

# Multi-Timeframe Arrays for Dashboard Mode (One-Pass Optimization)
declare -a DASH_TIERS_12H; declare -a DASH_TIERS_24H; declare -a DASH_TIERS_7D; declare -a DASH_TIERS_30D

collect_pihole_stats() {
    if [ "$SHOW_UNBOUND" == "only" ]; then return; fi
    if [ ! -r "$DBfile" ] && [ "$USE_SNAPSHOT" = false ]; then
        if [ "$SILENT_MODE" = false ]; then echo "âŒ Error: Cannot read database '$DBfile'. (Permission Denied - Try sudo)" >&2; fi
        [ "$DEBUG_MODE" = true ] && echo "[$(date)] DB Access Error: Cannot read $DBfile" >> "$DEBUG_LOG"
        for ((i=0; i<15; i++)); do TIER_COUNTS[$i]=0; TIER_PCTS[$i]="0.00"; done; return
    fi

    # Build Latency Cutoff Condition
    SQL_LATENCY_COND=""
    if [ -n "$MIN_LATENCY_CUTOFF" ]; then
        MIN_SEC=$(awk "BEGIN {print $MIN_LATENCY_CUTOFF / 1000}")
        SQL_LATENCY_COND="AND reply_time >= $MIN_SEC"
    fi
    if [ -n "$MAX_LATENCY_CUTOFF" ]; then
        MAX_SEC=$(awk "BEGIN {print $MAX_LATENCY_CUTOFF / 1000}")
        SQL_LATENCY_COND="$SQL_LATENCY_COND AND reply_time <= $MAX_SEC"
    fi

    SQL_BLOCKED_DEF="status IN (1, 4, 5, 9, 10, 11)"
    BASE_DEFAULT="2, 3, 6, 7, 8, 12, 13, 14, 15"; BASE_UPSTREAM="2, 6, 7, 8"; BASE_PIHOLE="3, 12, 13, 14, 15"

    if [[ "$MODE" == "UPSTREAM" ]]; then CURRENT_LIST="$BASE_UPSTREAM"; MODE_LABEL="Upstream Only"
    elif [[ "$MODE" == "PIHOLE" ]]; then CURRENT_LIST="$BASE_PIHOLE"; MODE_LABEL="Pi-hole Only"
    else CURRENT_LIST="$BASE_DEFAULT"; MODE_LABEL="All Normal Queries"; fi

    if [ "$EXCLUDE_NX" = true ]; then MODE_LABEL="$MODE_LABEL [Excl. Blocks]"; SQL_STATUS_FILTER="status IN ($CURRENT_LIST)";
    else [[ "$MODE" != "PIHOLE" ]] && SQL_STATUS_FILTER="status IN ($CURRENT_LIST, 16, 17)" || SQL_STATUS_FILTER="status IN ($CURRENT_LIST)"; fi

    # Create a specific filter for metrics/tiers that includes the latency cutoffs
    SQL_METRIC_FILTER="$SQL_STATUS_FILTER $SQL_LATENCY_COND"

    raw_limits=("$L01" "$L02" "$L03" "$L04" "$L05" "$L06" "$L07" "$L08" "$L09" "$L10" "$L11" "$L12" "$L13" "$L14" "$L15" "$L16" "$L17" "$L18" "$L19" "$L20")
    IFS=$'\n' sorted_limits=($(printf "%s\n" "${raw_limits[@]}" | grep -v '^$' | sort -n)); unset IFS
    if [ ${#sorted_limits[@]} -eq 0 ]; then sorted_limits=("0.009" "0.1" "1" "10" "50" "100" "300" "1000"); fi

    # TIER QUERY CONSTRUCTION
    sql_tier_cols=""; prev_ms="0"; prev_sec="0"; idx=0

    # Dashboard Optimization: Define time boundaries
    TS_NOW=$(date +%s)
    TS_12H=$((TS_NOW - 43200)); TS_24H=$((TS_NOW - 86400)); TS_7D=$((TS_NOW - 604800)); TS_30D=$((TS_NOW - 2592000))

    if [ "$DASH_MODE" = true ]; then
        # In Dash Mode, we broaden the search to 30 days and use Conditional Aggregation to fill all buckets in one pass
        QUERY_START="$TS_30D"; QUERY_END="$TS_NOW"
    fi

    for ms in "${sorted_limits[@]}"; do
        sec=$(awk "BEGIN {print $ms / 1000}")
        if [ "$idx" -eq 0 ]; then logic="reply_time <= $sec"; lbl="Tier $((idx+1)) (< ${ms}ms)"
        else logic="reply_time > $prev_sec AND reply_time <= $sec"; lbl="Tier $((idx+1)) (${prev_ms} - ${ms}ms)"; fi

        # Standard Column (Total for Query Range)
        # We use SQL_METRIC_FILTER to ensure cutoffs are applied to buckets
        [ -n "$sql_tier_cols" ] && sql_tier_cols="${sql_tier_cols}, "
        sql_tier_cols="${sql_tier_cols} SUM(CASE WHEN ${logic} AND $SQL_METRIC_FILTER THEN 1 ELSE 0 END)"

        if [ "$DASH_MODE" = true ]; then
            # Multi-Timeframe Columns (Aggregated in the same pass)
            sql_tier_cols="${sql_tier_cols}, SUM(CASE WHEN timestamp >= $TS_12H AND ${logic} AND $SQL_METRIC_FILTER THEN 1 ELSE 0 END)"
            sql_tier_cols="${sql_tier_cols}, SUM(CASE WHEN timestamp >= $TS_24H AND ${logic} AND $SQL_METRIC_FILTER THEN 1 ELSE 0 END)"
            sql_tier_cols="${sql_tier_cols}, SUM(CASE WHEN timestamp >= $TS_7D  AND ${logic} AND $SQL_METRIC_FILTER THEN 1 ELSE 0 END)"
            sql_tier_cols="${sql_tier_cols}, SUM(CASE WHEN timestamp >= $TS_30D AND ${logic} AND $SQL_METRIC_FILTER THEN 1 ELSE 0 END)"
        fi

        TIER_LABELS[$idx]="$lbl"; prev_ms="$ms"; prev_sec="$sec"; ((idx++))
    done

    # Last Tier (> Max)
    # The SQL_METRIC_FILTER will naturally exclude queries if they exceed MAX_LATENCY_CUTOFF
    lbl="Tier $((idx+1)) (> ${prev_ms}ms)"
    sql_tier_cols="${sql_tier_cols}, SUM(CASE WHEN reply_time > $prev_sec AND $SQL_METRIC_FILTER THEN 1 ELSE 0 END)"
    if [ "$DASH_MODE" = true ]; then
        sql_tier_cols="${sql_tier_cols}, SUM(CASE WHEN timestamp >= $TS_12H AND reply_time > $prev_sec AND $SQL_METRIC_FILTER THEN 1 ELSE 0 END)"
        sql_tier_cols="${sql_tier_cols}, SUM(CASE WHEN timestamp >= $TS_24H AND reply_time > $prev_sec AND $SQL_METRIC_FILTER THEN 1 ELSE 0 END)"
        sql_tier_cols="${sql_tier_cols}, SUM(CASE WHEN timestamp >= $TS_7D  AND reply_time > $prev_sec AND $SQL_METRIC_FILTER THEN 1 ELSE 0 END)"
        sql_tier_cols="${sql_tier_cols}, SUM(CASE WHEN timestamp >= $TS_30D AND reply_time > $prev_sec AND $SQL_METRIC_FILTER THEN 1 ELSE 0 END)"
    fi
    TIER_LABELS[$idx]="$lbl"

    ACTIVE_DB="$DBfile"; SNAP_FILE="/tmp/pi_snap_$$.db"
    if [ "$USE_SNAPSHOT" = true ]; then
        DB_SZ=$(du -k "$DBfile" | awk '{print $1}')
        FREE_RAM=$(free -k | awk '/^Mem:/{print $7}')
        [ -z "$FREE_RAM" ] && FREE_RAM=$(grep MemAvailable /proc/meminfo | awk '{print $2}')
        if [ "$FREE_RAM" -lt "$((DB_SZ + 51200))" ]; then SNAP_FILE="$HOME/pi_snap_$$.db"; fi
        sqlite3 "$DBfile" ".backup '$SNAP_FILE'" || exit 1
        ACTIVE_DB="$SNAP_FILE"
    fi

    # --- ERROR SUPPRESSION TRICK ---
    ERR_TMP=$(mktemp)
    # Added SUM(time^2) for Standard Deviation calculation
    SQL_OUT=$(sqlite3 "$ACTIVE_DB" <<EOF 2> "$ERR_TMP"
.mode list
.headers off
.timeout 30000
PRAGMA temp_store = MEMORY; PRAGMA synchronous = OFF;
CREATE TEMP TABLE raw AS SELECT timestamp, status, reply_time FROM queries WHERE timestamp >= $QUERY_START AND timestamp <= $QUERY_END $SQL_DOMAIN_CLAUSE;
CREATE TEMP TABLE mets AS SELECT 
    COUNT(*), SUM(CASE WHEN reply_time IS NULL THEN 1 ELSE 0 END), SUM(CASE WHEN reply_time IS NOT NULL THEN 1 ELSE 0 END),
    SUM(CASE WHEN reply_time IS NOT NULL AND $SQL_BLOCKED_DEF THEN 1 ELSE 0 END), 
    SUM(CASE WHEN reply_time IS NOT NULL AND $SQL_METRIC_FILTER THEN 1 ELSE 0 END),
    SUM(CASE WHEN reply_time IS NOT NULL AND $SQL_METRIC_FILTER THEN reply_time ELSE 0.0 END), 
    SUM(CASE WHEN reply_time IS NOT NULL AND $SQL_METRIC_FILTER THEN reply_time * reply_time ELSE 0.0 END),
    $sql_tier_cols
FROM raw;
SELECT * FROM mets;
SELECT reply_time FROM raw WHERE reply_time IS NOT NULL AND $SQL_METRIC_FILTER ORDER BY reply_time ASC LIMIT 1 OFFSET (SELECT (COUNT(*) - 1) / 2 FROM raw WHERE reply_time IS NOT NULL AND $SQL_METRIC_FILTER);
SELECT reply_time FROM raw WHERE reply_time IS NOT NULL AND $SQL_METRIC_FILTER ORDER BY reply_time ASC LIMIT 1 OFFSET (SELECT CAST((COUNT(*) * 0.95) - 1 AS INT) FROM raw WHERE reply_time IS NOT NULL AND $SQL_METRIC_FILTER);
EOF
)
    # Check stderr: Discard "interrupted" messages but show real errors
    if [ -s "$ERR_TMP" ]; then
        ERR_MSG=$(cat "$ERR_TMP")
        if [[ "$ERR_MSG" != *"interrupted"* ]]; then 
            echo "$ERR_MSG" >&2
            [ "$DEBUG_MODE" = true ] && echo "[$(date)] SQLite Error: $ERR_MSG" >> "$DEBUG_LOG"
        fi
    fi
    rm -f "$ERR_TMP"

    IFS='|' read -r -a METS <<< "$(echo "$SQL_OUT" | head -n 1)"
    P_TOTAL=${METS[0]:-0}; P_INVALID=${METS[1]:-0}; P_VALID=${METS[2]:-0}; P_BLOCKED=${METS[3]:-0}; P_ANALYZED=${METS[4]:-0}; P_DUR=${METS[5]:-0}; P_SQ_SUM=${METS[6]:-0}
    P_IGNORED=$((P_VALID - P_BLOCKED - P_ANALYZED))

    # Process Tier Data
    # Base offset is 7 (Added SQ_SUM). If DASH_MODE, we stride by 5. Else stride 1.
    if [ "$DASH_MODE" = true ]; then stride=5; else stride=1; fi
    base_idx=7

    for i in "${!TIER_LABELS[@]}"; do
        TIER_COUNTS[$i]=${METS[$base_idx]:-0}

        if [ "$DASH_MODE" = true ]; then
            DASH_TIERS_12H[$i]=${METS[$((base_idx+1))]:-0}
            DASH_TIERS_24H[$i]=${METS[$((base_idx+2))]:-0}
            DASH_TIERS_7D[$i]=${METS[$((base_idx+3))]:-0}
            DASH_TIERS_30D[$i]=${METS[$((base_idx+4))]:-0}
        fi

        if [ "$P_ANALYZED" -gt 0 ]; then 
            TIER_PCTS[$i]=$(awk "BEGIN {printf \"%.2f\", (${TIER_COUNTS[$i]} / $P_ANALYZED) * 100}")
        else TIER_PCTS[$i]="0.00"; fi

        base_idx=$((base_idx + stride))
    done

    # Calculate Average and Standard Deviation
    if [ "$P_ANALYZED" -gt 0 ]; then 
        P_AVG=$(awk "BEGIN {printf \"%.2f\", ($P_DUR * 1000) / $P_ANALYZED}")
        # Standard Deviation Formula: sqrt( (SumSq / N) - (Mean * Mean) )
        P_STD=$(awk "BEGIN {
            mean = $P_DUR / $P_ANALYZED;
            sq_mean = $P_SQ_SUM / $P_ANALYZED;
            var = sq_mean - (mean * mean);
            if (var < 0) var = 0;
            printf \"%.2f\", sqrt(var) * 1000;
        }")
    fi

    RAW_MED=$(echo "$SQL_OUT" | sed -n '2p'); RAW_95=$(echo "$SQL_OUT" | sed -n '3p')
    if [ -n "$RAW_MED" ]; then P_MED=$(awk "BEGIN {printf \"%.2f\", $RAW_MED * 1000}"); fi
    if [ -n "$RAW_95" ]; then P_95=$(awk "BEGIN {printf \"%.2f\", $RAW_95 * 1000}"); fi
    if [ "$USE_SNAPSHOT" = true ] && [ -f "$SNAP_FILE" ]; then rm "$SNAP_FILE"; fi
}
# --- 11. RENDERERS ---
print_text_report() {
    CURRENT_DATE=$(date "+%Y-%m-%d %H:%M:%S")
    declare -a L_LINES
    L_LINES+=("Time Period   : $TIME_LABEL"); L_LINES+=("Query Mode    : $MODE_LABEL"); L_LINES+=("-----------------------------------------------------")
    L_LINES+=("Total Queries        : $P_TOTAL")
    if [ "$P_TOTAL" -gt 0 ]; then PCT=$(awk "BEGIN {printf \"%.1f\", ($P_INVALID/$P_TOTAL)*100}"); L_LINES+=("Unsuccessful Queries : $P_INVALID ($PCT%)"); else L_LINES+=("Unsuccessful Queries : 0 (0.0%)"); fi
    L_LINES+=("Total Valid Queries  : $P_VALID")
    if [ "$P_VALID" -gt 0 ]; then
        # Modified to combine Blocked and Ignored logic using Total Queries as Base for Percentage
        SUM_BI=$((P_BLOCKED + P_IGNORED))
        if [ "$P_TOTAL" -gt 0 ]; then
            PCT=$(awk "BEGIN {printf \"%.1f\", ($SUM_BI/$P_TOTAL)*100}")
            L_LINES+=("Blocked / Ignored    : $P_BLOCKED / $P_IGNORED ($PCT%)")
            PCT=$(awk "BEGIN {printf \"%.1f\", ($P_ANALYZED/$P_TOTAL)*100}")
            L_LINES+=("Analyzed Queries     : $P_ANALYZED ($PCT%)")
        else
            L_LINES+=("Blocked / Ignored    : $P_BLOCKED / $P_IGNORED (0.0%)")
            L_LINES+=("Analyzed Queries     : $P_ANALYZED (0.0%)")
        fi
    else 
        L_LINES+=("Blocked / Ignored    : 0 / 0"); L_LINES+=("Analyzed Queries     : 0"); 
    fi
    L_LINES+=("Average Latency      : $P_AVG ms"); L_LINES+=("Standard Deviation   : $P_STD ms"); L_LINES+=("Median  Latency      : $P_MED ms"); L_LINES+=("95th Percentile      : $P_95 ms")

    declare -a R_LINES
    if [ "$HAS_UNBOUND" = true ]; then
        R_LINES+=("Server Status : $U_STATUS")
        if [[ "$U_STATUS" != *"Error"* ]]; then
            R_LINES+=("Config File   : /etc/unbound/unbound.conf"); R_LINES+=("---------------------------------------------") 
            R_LINES+=("Total Queries : $U_TOTAL"); R_LINES+=("Cache Hits    : $U_HITS ($U_PCT_HIT%)")
            R_LINES+=("Cache Misses  : $U_MISS ($U_PCT_MISS%)"); R_LINES+=("Prefetch Jobs : $U_PRE ($U_PCT_PRE% of Hits)")
            R_LINES+=(""); R_LINES+=("----- Cache Memory Usage (Used / Limit) -----")
            R_LINES+=("Msg Cache   : $(to_mb $U_MEM_MSG)MB / $(to_mb $U_LIM_MSG)MB  ($U_PCT_MEM_MSG%)")
            R_LINES+=("RRset Cache : $(to_mb $U_MEM_RR)MB / $(to_mb $U_LIM_RR)MB ($U_PCT_MEM_RR%)")
            if [ "$ENABLE_UCC" = true ]; then R_LINES+=("Messages (Queries): $UCC_MSG"); R_LINES+=("RRsets (Records)  : $UCC_RR"); fi
        else R_LINES+=(""); R_LINES+=("âš ï¸  Permission Denied or Service Down"); R_LINES+=("   Try running with 'sudo'"); fi
    fi

    if [ "$LAYOUT" == "horizontal" ]; then
        echo "===================================================================================================="
        TITLE="Pi-hole Latency Stats $VERSION"
        PAD=$(( (100 - ${#TITLE}) / 2 )); printf "%${PAD}s%s\n" "" "$TITLE"
        echo "===================================================================================================="
        DATE_STR="Analysis Date : $CURRENT_DATE"; PAD_DATE=$(( (100 - ${#DATE_STR}) / 2 )); printf "%${PAD_DATE}s%s\n" "" "$DATE_STR"
        echo "---------------- Pi-hole Performance ----------------||---------- Unbound DNS Performance ----------"
    else
        echo "========================================================"; echo "              Pi-hole Latency Stats $VERSION"; echo "========================================================"
        echo "Analysis Date : $CURRENT_DATE"
        if [ "$SHOW_UNBOUND" != "only" ]; then echo "Time Period   : $TIME_LABEL"; echo "Query Mode    : $MODE_LABEL"; fi
    fi

    if [ "$LAYOUT" == "horizontal" ]; then
        MAX=${#L_LINES[@]}; [ ${#R_LINES[@]} -gt $MAX ] && MAX=${#R_LINES[@]}
        for ((i=0; i<MAX; i++)); do printf "%-53s||%s\n" "${L_LINES[$i]}" "${R_LINES[$i]}"; done
        echo "----------------------------------------------------------------------------------------------------"
    else
        if [ "$SHOW_UNBOUND" != "only" ]; then
            echo "--------------------------------------------------------"
            for line in "${L_LINES[@]}"; do if [[ "$line" != Time* ]] && [[ "$line" != Query* ]] && [[ "$line" != ---* ]]; then echo "$line"; fi; done; echo ""
        fi
    fi

    if [ "$SHOW_UNBOUND" != "only" ]; then
        echo "--- Latency Distribution of Pi-Hole Analyzed Queries ---"
        MAX_LEN=0; for lbl in "${TIER_LABELS[@]}"; do [ ${#lbl} -gt $MAX_LEN ] && MAX_LEN=${#lbl}; done; MAX_LEN=$((MAX_LEN + 2))
        for i in "${!TIER_LABELS[@]}"; do printf "%-${MAX_LEN}s : %6s%%  (%s)\n" "${TIER_LABELS[$i]}" "${TIER_PCTS[$i]}" "${TIER_COUNTS[$i]}"; done
        if [ "$LAYOUT" == "horizontal" ]; then echo "===================================================================================================="; else echo "========================================================"; fi
    fi

    if [ "$LAYOUT" != "horizontal" ] && [ "$HAS_UNBOUND" = true ]; then
        if [ "$SHOW_UNBOUND" != "only" ]; then echo "              Unbound DNS Performance"; echo "========================================================"; fi
        for line in "${R_LINES[@]}"; do echo "$line"; done; echo "========================================================"
    fi
}

print_json_report() {
    CURRENT_DATE=$(date "+%Y-%m-%d %H:%M:%S")
    JSTR="{\"version\": \"$VERSION\", \"date\": \"$CURRENT_DATE\", \"time_period\": \"$TIME_LABEL\", \"mode\": \"$MODE_LABEL\""
    if [ -n "$DOMAIN_FILTER" ]; then JSTR="$JSTR, \"domain_filter\": \"$DOMAIN_FILTER\""; fi
    JSTR="$JSTR, \"stats\": {\"total_queries\": $P_TOTAL, \"unsuccessful\": $P_INVALID, \"total_valid\": $P_VALID, \"blocked\": $P_BLOCKED, \"ignored\": $P_IGNORED, \"analyzed\": $P_ANALYZED}"
    JSTR="$JSTR, \"latency\": {\"average\": $P_AVG, \"median\": $P_MED, \"p95\": $P_95, \"stddev\": $P_STD}"

    # Primary Tiers
    JSTR="$JSTR, \"tiers\": ["; FIRST=true
    for i in "${!TIER_LABELS[@]}"; do
        if [ "$FIRST" = true ]; then FIRST=false; else JSTR="$JSTR, "; fi
        JSTR="$JSTR{\"label\": \"${TIER_LABELS[$i]}\", \"count\": ${TIER_COUNTS[$i]}, \"percentage\": ${TIER_PCTS[$i]}}"
    done
    JSTR="$JSTR]"

    # Multi-Timeframe Tiers (Dash Mode Only)
    if [ "$DASH_MODE" = true ]; then
        build_tier_arr() {
            local -n arr=$1; local out="["; local f=true
            for k in "${!arr[@]}"; do [ "$f" = true ] && f=false || out="$out,"; out="$out${arr[$k]}"; done
            echo "$out]"
        }
        JSTR="$JSTR, \"tiers_12h\": $(build_tier_arr DASH_TIERS_12H)"
        JSTR="$JSTR, \"tiers_24h\": $(build_tier_arr DASH_TIERS_24H)"
        JSTR="$JSTR, \"tiers_7d\": $(build_tier_arr DASH_TIERS_7D)"
        JSTR="$JSTR, \"tiers_30d\": $(build_tier_arr DASH_TIERS_30D)"
    fi

    JSTR="$JSTR, \"unbound\": "
    if [ "$HAS_UNBOUND" = true ] && [[ "$U_STATUS" != *"Error"* ]]; then
        U_JSON="{\"status\": \"active\", \"total_hits\": $U_HITS, \"total_miss\": $U_MISS, \"prefetch\": $U_PRE, \"ratio\": $U_PCT_HIT, \"memory\": { \"msg\": { \"used_mb\": $(to_mb $U_MEM_MSG), \"limit_mb\": $(to_mb $U_LIM_MSG), \"percent\": $U_PCT_MEM_MSG }, \"rrset\": { \"used_mb\": $(to_mb $U_MEM_RR), \"limit_mb\": $(to_mb $U_LIM_RR), \"percent\": $U_PCT_MEM_RR } }, \"cache_count\": "
        if [ "$ENABLE_UCC" = true ]; then U_JSON="$U_JSON{ \"messages\": $UCC_MSG, \"rrsets\": $UCC_RR }"; else U_JSON="${U_JSON}null"; fi
        U_JSON="$U_JSON}"; JSTR="$JSTR$U_JSON"
    else JSTR="${JSTR}null"; fi
    JSTR="$JSTR}"; echo "$JSTR"
}

# --- 12. EXECUTION ---
if [ "$DEBUG_MODE" = true ]; then
    echo "[$(date)] --- DEBUG SESSION START $VERSION ---" > "$DEBUG_LOG"
    fix_perms "$DEBUG_LOG" "user"
fi

# Only run visual aids if NOT in silent mode AND connected to a real terminal
if [ "$SILENT_MODE" = false ] && [ "$SHOW_UNBOUND" != "only" ]; then
    if [ -t 1 ]; then
        echo -n "ðŸ“Š Analyzing Pi-hole database... " >&2
        tput sc >&2 2>/dev/null
        start_spinner
    else
        echo "ðŸ“Š Analyzing Pi-hole database..." >&2
    fi
fi

collect_unbound_stats
collect_pihole_stats

if [ "$SILENT_MODE" = false ] && [ "$SHOW_UNBOUND" != "only" ] && [ -n "$SPINNER_PID" ]; then 
    stop_spinner 
fi

TEXT_REPORT=$(print_text_report)
if [ "$DO_JSON" = true ]; then JSON_REPORT=$(print_json_report); fi

# --- HISTORY DATABASE LOGIC (Dash Mode Only) ---
if [ "$DASH_MODE" = true ] && [ "$DASH_HISTORY" = true ] && [ "$SHOW_UNBOUND" != "only" ]; then
    # Calculate Unbound Diffs
    DIFF_HITS=0; DIFF_MISS=0

    if [ -f "$SNAP_PATH" ]; then
        # FIXED: regex now allows for optional whitespace [[:space:]]* around the colon
        # piped to 'tr' to extract only digits, ensuring strict numeric output
        PREV_HITS=$(grep -o '"total_hits":[[:space:]]*[0-9]\+' "$SNAP_PATH" | tr -d -c 0-9)
        PREV_MISS=$(grep -o '"total_miss":[[:space:]]*[0-9]\+' "$SNAP_PATH" | tr -d -c 0-9)

        if [ -n "$PREV_HITS" ] && [ -n "$PREV_MISS" ]; then
            DIFF_HITS=$((U_HITS - PREV_HITS)); DIFF_MISS=$((U_MISS - PREV_MISS))
            # Handle restart/reset (negative diff)
            if [ "$DIFF_HITS" -lt 0 ]; then DIFF_HITS=0; fi
            if [ "$DIFF_MISS" -lt 0 ]; then DIFF_MISS=0; fi
        fi
    fi

    # Construct entry with new fields (Added stddev)
    # Note: We append stddev to the JSON, but history array structure isn't strictly defined, so adding it is fine.
    # However, older history entries simply won't have it.
    NEW_ENTRY=$(printf '{"version":"%s","date":"%s","average":%s,"median":%s,"p95":%s,"stddev":%s,"messages":%d,"rrsets":%d,"cache_mb_msg":%s,"cache_mb_rr":%s,"diff_hits":%d,"diff_miss":%d}' \
        "$VERSION" "$(date "+%Y-%m-%d %H:%M:%S")" "$P_AVG" "$P_MED" "$P_95" "$P_STD" "$UCC_MSG" "$UCC_RR" \
        "$(to_mb $U_MEM_MSG)" "$(to_mb $U_MEM_RR)" "$DIFF_HITS" "$DIFF_MISS")

    TMP_H=$(mktemp)
    if [ ! -f "$HIST_PATH" ] || [ ! -s "$HIST_PATH" ]; then
        echo "[$NEW_ENTRY]" > "$TMP_H"
    else
        (grep -o '{[^}]*}' "$HIST_PATH" 2>/dev/null; echo "$NEW_ENTRY") | tail -n "$MAX_HISTORY_ENTRIES" | tr '\n' ',' | sed 's/,$//; s/^/[/; s/$/]/' > "$TMP_H"
    fi
    mv "$TMP_H" "$HIST_PATH"
    fix_perms "$HIST_PATH" "dash"
fi

# --- OUTPUT HANDLING ---
if [ "$DASH_MODE" = true ]; then
    echo "$JSON_REPORT" > "$SNAP_PATH"
    fix_perms "$SNAP_PATH" "dash"
else
    # 1. Handle Text File Saving
    if [ "$DO_TXT" = true ] && [ -n "$TXT_FILE" ]; then
        [ "$ADD_TIMESTAMP" = true ] && TS=$(date "+%Y-%m-%d_%H%M") && TXT_FILE="${TXT_FILE%.*}_${TS}.${TXT_FILE##*.}"
        if [ "$SEQUENTIAL" = true ] && [ -f "$TXT_FILE" ]; then
            BASE="${TXT_FILE%.*}"; EXT="${TXT_FILE##*.}"; CNT=1
            while [ -f "${BASE}_${CNT}.${EXT}" ]; do ((CNT++)); done; TXT_FILE="${BASE}_${CNT}.${EXT}"
        fi
        echo "$TEXT_REPORT" > "$TXT_FILE"
        fix_perms "$TXT_FILE" "user"
    fi

    # 2. Handle JSON File Saving
    if [ "$DO_JSON" = true ] && [ -n "$JSON_FILE" ]; then
        [ "$ADD_TIMESTAMP" = true ] && TS=$(date "+%Y-%m-%d_%H%M") && JSON_FILE="${JSON_FILE%.*}_${TS}.${JSON_FILE##*.}"
        if [ "$SEQUENTIAL" = true ] && [ -f "$JSON_FILE" ]; then
            BASE="${JSON_FILE%.*}"; EXT="${JSON_FILE##*.}"; CNT=1
            while [ -f "${BASE}_${CNT}.${EXT}" ]; do ((CNT++)); done; JSON_FILE="${BASE}_${CNT}.${EXT}"
        fi
        echo "$JSON_REPORT" > "$JSON_FILE"
        fix_perms "$JSON_FILE" "user"
    fi

    # 3. Handle Screen Output (Independent of file saving)
    if [ "$SILENT_MODE" = false ]; then
        # If user asked for JSON on screen specifically
        if [ "$JSON_OUTPUT" = true ] && [ -z "$JSON_FILE" ]; then
            echo "$JSON_REPORT"
        else
            echo "$TEXT_REPORT"
        fi
    fi
fi

# AUTO-CLEAN LOGIC
if [ -n "$MAX_LOG_AGE" ] && [[ "$MAX_LOG_AGE" =~ ^[0-9]+$ ]]; then
    CLEANED=false
    if [ -n "$SAVE_DIR_TXT" ] && [ -d "$SAVE_DIR_TXT" ]; then find "$SAVE_DIR_TXT" -maxdepth 1 -type f -mtime +$MAX_LOG_AGE -delete; CLEANED=true; fi
    if [ -n "$SAVE_DIR_JSON" ] && [ -d "$SAVE_DIR_JSON" ]; then find "$SAVE_DIR_JSON" -maxdepth 1 -type f -mtime +$MAX_LOG_AGE -delete; CLEANED=true; fi
    if [ "$CLEANED" = true ] && [ "$SILENT_MODE" = false ]; then echo "Auto-Clean : Checked reports older than $MAX_LOG_AGE days"; fi
fi

# --- REPORT STATUS OUTPUT ---
if [ "$SILENT_MODE" = false ] && [ "$DASH_MODE" = false ]; then
    if [ "$DO_TXT" = true ] && [ -n "$TXT_FILE" ]; then echo -e "\033[1;36mText Report saved to: $TXT_FILE\033[0m" >&2; fi
    if [ "$DO_JSON" = true ] && [ -n "$JSON_FILE" ]; then echo -e "\033[1;36mJSON Report saved to: $JSON_FILE\033[0m" >&2; fi
fi

END_TS=$(date +%s.%N 2>/dev/null)
if [[ "$END_TS" == *N* ]] || [ -z "$END_TS" ]; then END_TS=$(date +%s); fi
DUR=$(awk "BEGIN {printf \"%.2f\", $END_TS - $START_TS}" 2>/dev/null); [ -z "$DUR" ] && DUR=$(( ${END_TS%.*} - ${START_TS%.*} ))
if [ "$SILENT_MODE" = false ]; then echo "Total Execution Time: ${DUR}s" >&2; 
	# echo "" ; 
fi

#CHECK FOR UPTADES
# --- Local Comparison ---
if [[ -f "$V_LOCAL_FILE" ]]; then
    # Get remote version string (e.g., 3.4)
    REMOTE_V=$(grep "^s=" "$V_LOCAL_FILE" | cut -d'=' -f2)

    # Strip non-numeric characters for comparison
    CLEAN_CUR=$(echo "$VERSION" | sed 's/[^0-9.]//g')
    CLEAN_REM=$(echo "$REMOTE_V" | sed 's/[^0-9.]//g')

    # If Remote version is higher than Current
    if [ "$(printf '%s\n' "$CLEAN_REM" "$CLEAN_CUR" | sort -V | head -n1)" != "$CLEAN_REM" ]; then
        YELLOW='\033[1;33m'
        NC='\033[0m'
        UPDATE_MSG=$(printf "${YELLOW}************************************************************${NC}\n${YELLOW}NEW UPDATE AVAILABLE: v${REMOTE_V}${NC}\n${YELLOW}Please visit: https://panoc.github.io/pihole-latency-stats/${NC}\n${YELLOW}************************************************************${NC}\n")
    fi
fi

if [ "$SILENT_MODE" = false ]; then 
    [ -n "$UPDATE_MSG" ] && printf "\n$UPDATE_MSG" >&2
    echo "" >&2
fi
